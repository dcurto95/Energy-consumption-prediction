{
  "test_name": "Increasing_GRU_Layers",
  "tunning_parameter": {
    "from": "arch",
    "name": "rnn_layers",
    "max_value": 20,
    "step": 1
  },
  "arch": {
    "neurons": 32,
    "neurons_increase": 2,
    "rnn": "GRU",
    "drop": 0.0,
    "rnn_layers": 2,
    "dense_layers": 1,
    "activation": "tanh",
    "activation_r": "hard_sigmoid",
    "window_size": 2
  },
  "training": {
    "batch": 1000,
    "epochs": 200,
    "optimizer": "adam",
    "lrate": 0.001
  }
}