{
  "test_name": "Increasing_SimpleLayers",
  "tunning_parameter": {
    "from": "arch",
    "name": "rnn_layers",
    "max_value": 10,
    "step": 1
  },
  "arch": {
    "neurons": 32,
    "neurons_increase": 2,
    "rnn": "SimpleRNN",
    "drop": 0.0,
    "rnn_layers": 1,
    "dense_layers": 1,
    "activation": "tanh",
    "activation_r": "hard_sigmoid"
  },
  "training": {
    "batch": 1000,
    "epochs": 10,
    "optimizer": "adam",
    "lrate": 0.001
  }
}